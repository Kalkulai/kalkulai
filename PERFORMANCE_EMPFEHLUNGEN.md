# Performance-Empfehlungen: Retriever-Konfiguration

## üìä Performance-Vergleich

| Methode | Latenz | Qualit√§t | Ressourcen | Beste f√ºr |
|---------|--------|----------|------------|-----------|
| **Nur Hybrid (BM25+Lexical+RRF)** | ~20ms | ‚≠ê‚≠ê‚≠ê‚≠ê | Niedrig | Schnelle Suchen, Tippfehler |
| **Nur Vector Search** | ~50-100ms | ‚≠ê‚≠ê‚≠ê‚≠ê | Mittel | Semantische Suche |
| **Hybrid + Vector + RRF** | ~70-120ms | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | Hoch | Beste Qualit√§t |
| **Kein Retriever** | ~0ms | ‚≠ê‚≠ê | Sehr niedrig | Schnellster Chat |

*Latenz-Werte basieren auf typischen Kataloggr√∂√üen (100-1000 Produkte)*

---

## üéØ Empfehlungen nach Use-Case

### 1. **LLM1 Chat (Interaktive Konversation)**

**Priorit√§t**: Geschwindigkeit > Qualit√§t

#### **Option A: Schnellste Performance** ‚ö°
```bash
LLM1_THIN_RETRIEVAL=0
```
- **Latenz**: ~0ms (kein Retriever)
- **Qualit√§t**: ‚≠ê‚≠ê (nur LLM + Memory)
- **Use-Case**: Schnelle Chat-Antworten, keine Produktvorschl√§ge n√∂tig
- **Vorteil**: Sehr schnell, niedrige Kosten

#### **Option B: Beste Balance** ‚öñÔ∏è (EMPFOHLEN)
```bash
LLM1_THIN_RETRIEVAL=1
```
- **Latenz**: ~20ms (Hybrid Search)
- **Qualit√§t**: ‚≠ê‚≠ê‚≠ê‚≠ê (BM25 + Lexical + RRF)
- **Use-Case**: Chat mit Produktvorschl√§gen
- **Vorteil**: Schnell + gute Qualit√§t, deterministisch

#### **Option C: Maximale Qualit√§t** üéØ
```bash
LLM1_THIN_RETRIEVAL=1
COMBINE_HYBRID_VECTOR=1  # Falls in LLM1 integriert
```
- **Latenz**: ~70-120ms (Hybrid + Vector)
- **Qualit√§t**: ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê
- **Use-Case**: Wenn Qualit√§t wichtiger als Geschwindigkeit
- **Nachteil**: Deutlich langsamer

**üèÜ Empfehlung f√ºr LLM1**: **Option B** (`LLM1_THIN_RETRIEVAL=1`)
- Beste Balance zwischen Geschwindigkeit und Qualit√§t
- 20ms ist f√ºr Chat-Interaktionen akzeptabel
- Gute Tippfehlerkorrektur und Synonym-Erkennung

---

### 2. **LLM2 Angebotsgenerierung**

**Priorit√§t**: Qualit√§t > Geschwindigkeit

#### **Aktuell**: Nur Vector Search
```python
# quote_service.py, Zeile 3424
hits = ctx.retriever.get_relevant_documents(t)[:8]
```
- **Latenz**: ~50-100ms
- **Qualit√§t**: ‚≠ê‚≠ê‚≠ê‚≠ê (nur semantisch)
- **Problem**: Verpasst exakte Matches, keine Tippfehlerkorrektur

#### **Option A: Hybrid + Vector kombiniert** üéØ (EMPFOHLEN)
```bash
COMBINE_HYBRID_VECTOR=1
```
- **Latenz**: ~70-120ms
- **Qualit√§t**: ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê (BM25 + Lexical + Vector + RRF)
- **Vorteil**: 
  - Deckt alle F√§lle ab (exakt, fuzzy, semantisch)
  - Beste Recall-Rate
  - Bessere Angebotsqualit√§t
- **Nachteil**: ~20-50ms langsamer

**üèÜ Empfehlung f√ºr LLM2**: **Hybrid + Vector kombiniert**
- Qualit√§t ist wichtiger als Geschwindigkeit bei Angebotsgenerierung
- 70-120ms ist akzeptabel (nicht interaktiv)
- Deutlich bessere Ergebnisse durch Kombination

---

### 3. **API `/api/catalog/search`**

**Priorit√§t**: Balance zwischen Geschwindigkeit und Qualit√§t

#### **Option A: Schnell** ‚ö°
```bash
COMBINE_HYBRID_VECTOR=0  # Default
```
- **Latenz**: ~20ms (nur Hybrid Search)
- **Qualit√§t**: ‚≠ê‚≠ê‚≠ê‚≠ê
- **Use-Case**: Schnelle API-Antworten, typische Suchen

#### **Option B: Beste Qualit√§t** üéØ (EMPFOHLEN)
```bash
COMBINE_HYBRID_VECTOR=1
```
- **Latenz**: ~70-120ms
- **Qualit√§t**: ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê
- **Use-Case**: Wenn API-Qualit√§t wichtig ist
- **Vorteil**: Deckt alle Suchszenarien ab

**üèÜ Empfehlung f√ºr API**: **Option B** (`COMBINE_HYBRID_VECTOR=1`)
- API-Calls sind nicht interaktiv (kein User wartet direkt)
- Bessere Qualit√§t rechtfertigt zus√§tzliche Latenz
- Kann bei Bedarf per Request-Parameter deaktiviert werden

---

## üìà Performance-Optimierungen

### 1. **Caching**
- **Hybrid Search**: Cache-TTL 60s (bereits implementiert)
- **Vector Search**: Index-Cache pro Company (bereits implementiert)
- **Empfehlung**: Cache-TTL beibehalten

### 2. **Pre-Filtering**
- Test-Produkte werden fr√ºh ausgefiltert ‚úÖ
- Inactive Products werden ignoriert ‚úÖ
- **Empfehlung**: Beibehalten (reduziert Suchraum)

### 3. **Parallelisierung**
- BM25 + Lexical k√∂nnen parallel laufen
- Vector Search kann parallel zu BM25/Lexical laufen
- **Aktuell**: Sequenziell implementiert
- **Potenzial**: ~30-40% Geschwindigkeitsgewinn m√∂glich

### 4. **Index-Gr√∂√üe**
- BM25 Index: In-Memory (sehr schnell)
- Vector Index: In-Memory (DocArray)
- **Empfehlung**: Bei >10.000 Produkten ‚Üí Externe Vector-DB (Pinecone, Weaviate)

---

## üéØ Finale Empfehlungen

### **Produktions-Setup** (Beste Balance)

```bash
# LLM1: Schnell mit guten Vorschl√§gen
LLM1_THIN_RETRIEVAL=1

# LLM2: Beste Qualit√§t (wichtig f√ºr Angebote)
COMBINE_HYBRID_VECTOR=1

# API: Beste Qualit√§t
COMBINE_HYBRID_VECTOR=1
```

**Erwartete Performance**:
- **LLM1 Chat**: ~20ms (Hybrid Search)
- **LLM2 Angebot**: ~70-120ms (Hybrid + Vector)
- **API Search**: ~70-120ms (Hybrid + Vector)

### **Performance-kritisches Setup** (Schnellste Option)

```bash
# LLM1: Kein Retriever (schnellster Chat)
LLM1_THIN_RETRIEVAL=0

# LLM2: Nur Vector (schneller als kombiniert)
COMBINE_HYBRID_VECTOR=0

# API: Nur Hybrid (schnell)
COMBINE_HYBRID_VECTOR=0
```

**Erwartete Performance**:
- **LLM1 Chat**: ~0ms (kein Retriever)
- **LLM2 Angebot**: ~50-100ms (nur Vector)
- **API Search**: ~20ms (nur Hybrid)

### **Qualit√§ts-Setup** (Beste Ergebnisse)

```bash
# LLM1: Hybrid mit Vorschl√§gen
LLM1_THIN_RETRIEVAL=1

# LLM2: Hybrid + Vector kombiniert
COMBINE_HYBRID_VECTOR=1

# API: Hybrid + Vector kombiniert
COMBINE_HYBRID_VECTOR=1
```

**Erwartete Performance**:
- **LLM1 Chat**: ~20ms (Hybrid Search)
- **LLM2 Angebot**: ~70-120ms (Hybrid + Vector)
- **API Search**: ~70-120ms (Hybrid + Vector)

---

## üîç Performance-Metriken messen

### Benchmark-Query-Beispiele:
```python
# Exakter Match
"Dispersionsfarbe wei√ü"

# Tippfehler
"Disperionsfarbe weiss"

# Semantisch √§hnlich
"Au√üenfarbe f√ºr Fassade"

# Synonym
"Tiefengrund" vs "Tiefgrund"
```

### Erwartete Ergebnisse:
- **Hybrid Search**: Gut bei exakten Matches + Tippfehlern
- **Vector Search**: Gut bei semantischer √Ñhnlichkeit
- **Kombiniert**: Gut bei allen Szenarien

---

## üí° Zusammenfassung

**Beste Performance = Beste Balance**:

1. **LLM1**: `LLM1_THIN_RETRIEVAL=1` (Hybrid Search)
   - Schnell genug (~20ms)
   - Gute Qualit√§t
   - Deterministisch

2. **LLM2**: `COMBINE_HYBRID_VECTOR=1` (Hybrid + Vector)
   - Beste Qualit√§t f√ºr Angebote
   - Latenz akzeptabel (~70-120ms)
   - Deckt alle F√§lle ab

3. **API**: `COMBINE_HYBRID_VECTOR=1` (Hybrid + Vector)
   - Beste Qualit√§t
   - Nicht interaktiv (Latenz weniger kritisch)

**Warum diese Kombination?**
- ‚úÖ LLM1: Geschwindigkeit wichtig ‚Üí Hybrid Search reicht
- ‚úÖ LLM2: Qualit√§t wichtig ‚Üí Kombiniert f√ºr beste Ergebnisse
- ‚úÖ API: Qualit√§t wichtig ‚Üí Kombiniert f√ºr beste Ergebnisse

**Trade-off**: 
- ~50-100ms zus√§tzliche Latenz bei LLM2/API
- Deutlich bessere Qualit√§t rechtfertigt dies

---

**Stand**: 2025-01-27  
**Version**: 1.0


